{"title":"NFL Losers Pool - 2022","markdown":{"yaml":{"title":"NFL Losers Pool - 2022","date":"2022-09-07","slug":[],"categories":["R","Sports Analytics","Data Visualization"],"tags":["R","Sports Analytics","Data Visualization"],"meta_img":"image/image.png","description":"Optimizing fantasy picks in an annual NFL losers pool.","output":{"html_document":{"toc":true,"toc_float":{"collapsed":false,"smooth_scroll":false},"code_folding":"hide"}}},"headingText":"Parameters","containsRefs":false,"markdown":"\n\n<!-- <style type=\"text/css\"> -->\n\n<!--    .main-container {max-width: 50%;} -->\n\n<!--    .row {display: flex;} -->\n\n<!--    .column {flex: 50%;} -->\n\n<!-- </style> -->\n\n<!-- {{ $readTime := mul (div (countwords .Content) 220.0) 60 }} -->\n\n<!-- {{ $minutes := math.Floor (div $readTime 60) }} -->\n\n<!-- {{ $seconds := mod $readTime 60 }} -->\n\n<!-- <p>Reading time: {{ $minutes }} {{ cond (eq $minutes 1) \"minute\" \"minutes\" }} and -->\n\n<!--     {{ $seconds }} {{ cond (eq $seconds 1) \"second\" \"seconds\" }}.</p> -->\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, \n                      warning = FALSE, \n                      message = FALSE, \n                      echo = FALSE, \n                      fig.align = \"center\", \n                      out.width=\"80%\")\n\npacman::p_load(googlesheets4, ggplot2, dplyr, data.table, tidyr, kableExtra)\n\ntheme_set(\n  theme_bw() + \n  theme(\n    panel.grid.major = element_blank(), \n    # axis.ticks.y = element_blank(),\n    plot.title=element_text(size = 16, face=\"bold\"),\n    plot.title.position = \"plot\",\n    plot.subtitle=element_text(face=\"italic\", size=12, margin=margin(b=12)),\n    plot.caption=element_text(size=8, margin=margin(t=8), color=\"#7a7d7e\"), \n    legend.position = \"bottom\"\n    )\n)\n\ncumprob = function(picks, inc_weeks = FALSE){\n  purrr::accumulate((1-picks$pwin), function(x, y)  x * y)\n}\n\npath = \"https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv\"\n\n\nSTART_WEEK = 3\nNUM_WEEKS = 12\n\neliminations = data.frame(week = c(    1,     1,     1,     1,     2,     2,     3,     3,     3,     4,      6,     6,     7,     7), \n                          pick = c(\"PIT\", \"NYG\", \"SEA\", \"CLE\", \"DAL\", \"MIA\", \"IND\", \"JAX\", \"DAL\", \"NYJ\",  \"NYJ\", \"ATL\", \"CAR\", \"CLE\"))\n\ncolor_scheme = \"D\" # for scale_virdis\n\npast_picks = data.frame(week = c(1, 2), \n                   team1 = c(\"PIT\", \"CHI\"),\n                   team2 = c(\"PIT\", \"CHI\"))\n```\n\nComing out of of Labour Day weekend only means one thing, it is time again for the annual NFL Losers Pool competition. This is the second time I am writing about this type of competition. You can see my blog post about trying to draft an optimal lineup here: [2021 NFL Losers Pool](https://www.jordanhutchings.com/blog/2021-11-19-nfl-fantasy-losers-pool/).\n\nBelow are the rules for our 2022 contest.\n\n## Losers Pool Rules\n\n1.  You must pick exactly one team per week to lose their game.\n2.  You cannot pick the same team more than once per season.\n3.  If your team wins their game, you are eliminated.\n4.  Rebuys back into the competition are allowed for Weeks 1 and 2.\n5.  You may enter up to three sets of picks.\n\n## Pick Optimization\n\nThe objective of this competition is to outlast the other competitors in the pool. Specifically, this means avoiding elimination and being the remaining player in the pool. The second point is worth noting because we will shift our strategy from simply minimizing the risk of our picks losing, to maximizing the likelihood that our picks move on relative to the picks of others in the pool. A quick foreshadowing - this will involve using *team ownership* to trade-off probability of making it to the next week for increasing our expected value in the competition.\n\nThere are a total of 32 teams to choose from, and we can expect the pool to run for roughly 10 weeks - going off of last years competition. This is a large number of potential combinations of teams to select in each week. In fact for 10 weeks, it is $32 \\times 31 \\times ... \\times 22$ which is roughly 234 trillion combinations (I'm not including teams with bye weeks but you get the idea, the space of possible picks is very large).\n\nFortunately, we can be smart about our optimization, and conditional on game forecasts, reach the global optimum without much computation work. I use two different algorithms to compare pick schedules; what I call the Opportunity Cost Model and Greedy Model. The Greedy Model will out preform the Opportunity Cost model in the short run, but eventually the Opportunity Cost model will pass the Greedy Model in future weeks.\n\n1.  **Opportunity Cost Model** - picking the lowest win probability team in a given week conditional on it having the largest distance to the second lowest win probability that same week.\n\n2.  **Greedy Model** - Picking the team with the lowest win probability in the first week, then the second, and so on...\n\n**Opportunity Cost Model Algorithm**\n\n1.  Step 1: Compute the difference between the least and second least likely teams to win in each week for each team and week in the pool.\n2.  Step 2: Pick the team & week combination with the largest difference between the least and second least likely teams.\n3.  Step 3: Remove the week and team combination from the pool and repeat Steps 1 & 2 until all weeks are filled.\n\n![](oc-anim.gif) <!--Speed up the gif speed, change dimensions in the r file to make fill the page --> <!-- There is some weird error where teams are disappearing in between stages -->\n\n**Greedy Model Algorithm**\n\n1.  Step 1: Start at the earliest week we wish to optimize over.\n2.  Step 2: Pick the team with the lowest probability of winning, and remove this team from the candidate pool.\n3.  Step 3: Move on to the next week, and repeat Steps 2 and 3 until we reach the terminal week.\n\n![](naive-anim.gif)\n\n## Making Picks\n\nLets put the above algorithms to action. Like last year, I am using the [FiveThirtyEight NFL Projections](https://projects.fivethirtyeight.com/2022-nfl-predictions/) to estimate each teams likelihood of winning their game. These ratings are based off of each teams computed ELO score, with some additional adjustments - read about their methodology [here](https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/).\n\nWe can see that there are some clear weeks below with drastic underdogs, and each week after Week 1 contains at least one game with a win probability less than 25%.\n\n```{r}\n# tidy data to be: week | team | prob win\ndata = fread(path)\ndata[, week := floor(as.numeric(difftime(date + 1, \"2022-09-08\", units=\"days\")) / 7) + 1]\ndata = data[, .(week, team1, team2, qbelo_prob1, qbelo_prob2)]\nteam1 = data[, .(week, team1, qbelo_prob1)]\nteam2 = data[, .(week, team2, qbelo_prob2)]\nplot_data = rbind(team1 |> select(week, team = team1, pwin = qbelo_prob1), \n                  team2 |> select(week, team = team2, pwin = qbelo_prob2))\n\nplot_data |> \n  group_by(team) |>\n  mutate(avg_p = mean(pwin), \n         tag = ifelse(pwin < 0.25, \"X\", \"\")) |> \n  ungroup() |> \n  mutate(team = reorder(team, avg_p)) |> \n  ggplot(aes(x = week, y = team, fill = pwin)) + \n  geom_tile() + \n  geom_text(aes(label = tag, x = week, y = team), color = \"white\") + \n  theme(legend.position = \"right\") + \n  scale_fill_viridis_c(\"Win Probability\", labels = scales::percent_format(), option = color_scheme) + \n  labs(title = \"Heatmap of Win Probabilities - By Team and Week\", \n       subtitle = \"White crosses represent win probabilities less than 25%\",\n       caption = \"QB ELO probabilities used taken from FiveThirtyEight NFP 2022 Predictions.\\nRows are sorted by the average win probability across all games.\",\n       x = \"Week Number\", \n       y = \"\") + \n  scale_x_continuous(expand = c(0, 0), breaks = 1:18)\n```\n\nI choose to run the above two algorithms starting in Week 3. Since we can rebuy back into the competition in Weeks 1 and 2, we do not want to take a valuable pick from our elimination weeks. Therefore, I make my set of picks on weeks 3 through 10, then pick Week 1 and 2 after removing the Weeks 3 - 10 picks, this ended up being the Pittsburgh Steelers and Chicago Bears.\n\nThe pick schedules using both algorithms are shown below. Notice the trade off of early week win probabilities for later risk savings.\n\n```{r, compare-algos}\n# Throw downloading data into a tryCatch so we can use a local copy w/o internet\nread_data = function(path, init_week = \"2022-09-08\") {\n  cols = c(\"date\", \"season\", \"team1\", \"team2\", \"qbelo_prob1\", \"qbelo_prob2\")\n  dt = fread(path, select = cols)\n  dt |> \n    mutate(pwin = pmin(qbelo_prob1, qbelo_prob2), \n           team = case_when(\n             qbelo_prob1 < qbelo_prob2 ~ team1, \n             qbelo_prob1 >= qbelo_prob2 ~ team2,\n             TRUE ~ \"ERROR\"), \n           week = floor(as.numeric(difftime(date + 1, init_week, units=\"days\")) / 7) + 1) |> \n    select(-c(team1, team2, qbelo_prob1, qbelo_prob2))}\n  \n\npath = \"https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv\"\ndf = read_data(path)\n\n# use previously downloaded data to keep the elo chart consistent\n# df = fread(\"elo_predictions.csv\")\n\n# Opportunity Cost Model ----\ndelta = function(week_num, picks) {\n  \n  tmp = arrange(df[week == week_num & !team %in% picks$pick], pwin) # sort and filter for a given week\n  score = tmp[2, ]$pwin - tmp[1, ]$pwin # compute oc of best pick\n  \n  data.frame(\n    pick = tmp[1]$team,\n    score = score, \n    week = week_num,\n    pwin = tmp[1]$pwin\n  )\n    \n}\n\npicks_by_oc = function(NUM_WEEKS = 12, START_WEEK = 3) {\n  \n  picks = data.frame()\n  \n  for(i in START_WEEK:NUM_WEEKS) {\n    weeks = seq(START_WEEK, NUM_WEEKS, 1)[!seq(START_WEEK, NUM_WEEKS, 1) %in% picks$week]\n    rankings = lapply(weeks, function(x) delta(x, picks)) |> bind_rows()\n    pick = rankings[rank(-rankings$score) == 1, ]\n    picks = rbind(picks, pick)\n  }\n  \n  arrange(picks, week)\n}\n\npicks_oc = picks_by_oc(NUM_WEEKS, START_WEEK)\npicks_oc$cumprob = cumprob(picks_oc)\n\n# Greedy Model ----\npicks_by_naive = function(NUM_WEEKS = 12, START_WEEK = 3) {\n  \n  picks_naive = data.frame()\n  \n  for(i in START_WEEK:NUM_WEEKS) {\n  \n    tmp = arrange(df[week == i & !team %in% picks_naive$pick], pwin)\n    \n    pick = data.frame(\n      pick = tmp[1]$team,\n      week = i,\n      pwin = tmp[1]$pwin\n    )\n    \n    picks_naive = rbind(picks_naive, pick)\n    \n  }\n  arrange(picks_naive, week)\n}\n\n# compute the likelihood of reaching the next week\npicks_naive = picks_by_naive(NUM_WEEKS, START_WEEK)\npicks_naive$cumprob = cumprob(picks_naive)\n\n# Join models ----\npicks = rbind(picks_oc |> select(-score) |> mutate(label = \"OC\"), \n              picks_naive |> mutate(label = \"Greedy\"))\n\n# Plot results \npicks |> \n  group_by(week) |>\n  mutate(d = lag(pwin) - pwin, # compute difference between pick probs\n         y_pos = (lag(pwin) + pwin)/2,  # compute the positioning to be in the middle of picks\n         y_label = ifelse(d == 0, \"\", paste0(round(d * 100, 1), \"%\")), \n         pick = ifelse(y_label == \"\" & !is.na(y_label), \"\", pick)) |> # only show label for one of two identical picks\n  ggplot(aes(x = week, y = pwin, color = label, label = y_label)) + \n  geom_line(aes(group = week), color=\"#e3e2e1\", size = 2, alpha = 0.7) + \n  geom_point(size = 3) + \n  geom_text(aes(x = week, y = y_pos), color = \"#414a4c\", nudge_x = 0.4) + \n  ggrepel::geom_text_repel(aes(x = week, y = pwin, label = pick), nudge_x = 0.3, color = \"#414a4c\", direction = \"y\") + \n  scale_color_viridis_d(option = color_scheme) + \n  scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) + \n  scale_y_continuous(labels = scales::percent_format(), n.breaks = 10) +\n  labs(title = \"Week-by-Week Win Probabilities across Models\", \n       subtitle = \"Showing the change in probabilities for each approach\",\n       caption = \"Differences are interepreted as the additional risk taken on by selecting the OC model.\\nData is updated weekly, and so predictions in plot are subject to change.\",\n       x = \"Week Number\", \n       y = \"Win Probability\", \n       color = \"Model\") + \n  theme(legend.position=c(.105,.15), \n        legend.background = element_blank())\n```\n\nWe can compare the performance of both algorithms by comparing the likelihoods of reaching a given week for both models. The likelihood we move on from a given week $w$ is equal to the probability $P(W\\leq w)$ where,\n\n```{=tex}\n\\begin{align*}\nP(W\\leq w) &= \\Pi_{w=3}^{12} p_{i, w}\\cdot x_{i, w} \\\\ \n\\text{Subject to } & \\sum_i x_{i, w} = 1 \\\\\n& \\sum_w x_{i, w} \\leq 1\n\\end{align*}\n```\nWhich is the likelihood a given schedule of picks reaches week 10 subject to being able to pick only one team per week, and picking any given team at most once.\n\n<!-- $$P(W\\leq w) = \\Pi_{t=3}^{10} p_{i, w}\\cdot x_{i, w}$$ where $p_{i,w}$ is the likelihood the $i^{th}$ selected team loses their game in week $w$.  -->\n\n```{r, cumprob-plot, eval=FALSE}\n\n# data changed, so using screengrab of past version of the plot\npicks |> \n  ggplot(aes(x = week, y = cumprob, color = label)) + \n  geom_point() + \n  geom_line() + \n  scale_color_viridis_d(option = color_scheme) + \n  scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) + \n  scale_y_continuous(labels = scales::percent_format(), n.breaks = 10) +\n  labs(title = \"Week-by-Week Win Probabilities across Models\", \n       subtitle = \"Showing the change in probabilities for each approach\",\n       caption = \"Differences are interepreted as the additional risk taken on by selecting the OC model.\",\n       x = \"Week Number, w\", \n       y = \"P(W <= w)\", \n       color = \"Model\") + \n  theme(legend.position=c(.935,.85), \n        legend.background = element_blank())\n```\n\n![](cumprob-plot-1.png)\n\n## Optimal Decisions under Multiple Entries\n\nOne interesting aspect of the Losers Pool is that we are able to submit multiple submissions into the competition. The above analysis works for the Single-Entry case, however things become more complex in the Multiple-Entry case. When dealing with multiple entries, I move from minimizing the cost of being eliminated in any given week, to minimizing the likelihood all of the entries are eliminated in a given week. We can represent each combination of an N-team tuple as a possible pick in a given week, and calculate the probability of at least one team moving onto the next week from a tuple of N picks. Given we have two entries in the competition, this is equal to $1 - (p_{i, w} \\cdot x_{i, w})(p_{j, w} \\cdot x_{j, w})$.\n\nBy computing the above likelihoods of each tuple moving onto the following week, we can then run the Opportunity Cost model on the set of picks, taking the pick with the largest difference between the best and second best pick across all weeks we are considering.\n\n<!-- $$\\mathrm{P(\\text{At least one team loses})}_{i\\in \\mathcal I, w} = 1 - \\Pi_{i \\in \\mathcal I, w}(p_{i, w}\\cdot x_{i, w})$$ -->\n\n<!-- Where $\\mathcal I$ is the set of teams considered in the tuple for week $w$. Using the above notation, our objective function becomes:  -->\n\n<!-- \\begin{align*} -->\n\n<!-- & \\max_{}\\Pi_{w=3}^{10} 1 - \\Pi_{i \\in \\mathcal I, w}(p_{i, w}\\cdot x_{i, w}) -->\n\n<!-- \\text{Subject to} &  -->\n\n<!-- \\end{align*} -->\n\n```{r, multi-entries}\n\n# make data of permutations of combinations\ndf = df[, .(week, team, pwin)]\n\ncross_data = data.frame()\nsetDT(cross_data)\n\nfor(w in unique(df$week)) {\n\n  tmp = df[week == w, ]\n  \n  for(row in 1:nrow(tmp)) {\n    team1 = tmp[row, ]\n    out = merge(tmp, team1, by = \"week\", all.x = TRUE, suffixes = c(\"1\", \"2\"))\n    cross_data = rbind(cross_data, out)\n  }\n  \n}\n\ncross_data[team1 != team2, value := (1 - pwin1 * pwin2)]\ncross_data[team1 == team2, value := (1 - pwin1)]\n\n# plot\np = cross_data |> \n  filter(week %in% START_WEEK:NUM_WEEKS) |> \n  mutate(week_label = paste(\"Week\", week), \n         week_label = reorder(week_label, rank(week))) |> \n  ggplot(aes(x = team1, y = team2, fill = value)) + \n  geom_tile() + \n  scale_fill_viridis_c(label = scales::percent_format(), direction = -1) + \n  theme(axis.text.x = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks = element_blank()) + \n  facet_wrap(.~week_label, nrow = 2, scales=\"free\") + \n  labs(title = \"Likelihood of moving on through the week\", \n       subtitle = \"Weeks shown as facets - the darker the better\", \n       fill = \"Prob at least one team loses\", \n       caption = \"Team labels removed for each week simply to demonstrate how to visualize the comparisons\", \n       x = \"\", \n       y = \"\") + \n  theme(legend.position = \"none\")\n\n# extra steps to center plotly\npp <- plotly::ggplotly(p)    # As before\nhtmltools::div( pp, align=\"center\" )  # Result is now an HTML object\n\n # plotly drops the subtitle, and caption\n```\n\n*The above plot has its axis removed, however is interactive. By hovering each cell you can see the pick tuple as well as the likelihood one of the two teams moves on. The darker the cell, the greater the likelihood of at least one team losing their game that week.*\n\nSome observations:\n\n-   It is almost always best to diversify your picks. Despite Atlanta having a low win rate in Week 5, combinations of picking Atlanta and another team still dominate picking Atlanta.\n-   The matrix is symmetric, however ordering of picks matters as picking a team in the first spot can still allow for the same team to be picked in the second spot. i.e. (DET, JAX) and (JAX, DET) are valid in consecutive weeks.\n\nAs above, we can compare the performance of the OC model with the Greedy Model in the Multi-Entry case. The below plot is in terms of the likelihood of moving onto the following week, and so a higher is better. As with the Single-Entry case, we can see the OC model trading off some early likelihood for greater future likelihoods of having at least one team move onto the next week.\n\n```{r}\n# cross_data |> \n#   filter(week %in% START_WEEK:NUM_WEEKS) |>\n#   mutate(label = paste(team1, team2)) |> \n#   ggplot(aes(x = week, y = value)) + \n#   geom_point(alpha = 0.1) + \n#   scale_y_continuous(labels = scales::percent_format()) + \n#   scale_x_continuous(breaks = 3:10) + \n#   labs(title = \"Likelihood of moving on from a given week\", \n#        subtitle = \"Each point represents a set of two possible picks in a given week\", \n#        x = \"Week Number\", \n#        y = \"Pr(At Least One Submission Moving on)\") \n\n\n# remove prev picked teams or weeks out of samples\npool = cross_data[week %in% START_WEEK:NUM_WEEKS &\n  !week %in% past_picks$week &\n  !team1 %in% past_picks$team1 &\n  !team2 %in% past_picks$team2, ]\n\n# compute the distance between the best and second best pick per week\ndelta_mult = function(week_num, picks) {\n  \n  tmp = arrange(pool[week == week_num & !team1 %in% picks$pick1 & !team2 %in% picks$pick2], -value)\n  # logic to not count the value below if they're the same - as we have the same game with team1 and team2 flipped\n  if (tmp[1, ]$value == tmp[2, ]$value) {\n    score = tmp[1, ]$value - tmp[3, ]$value\n  } else {\n    score = tmp[1, ]$value - tmp[2, ]$value\n  }\n  \n  data.frame(week = week_num,\n             pick1 = tmp[1, ]$team1, \n             pick2 = tmp[1, ]$team2, \n             pwin1 = tmp[1, ]$pwin1, \n             pwin2 = tmp[1, ]$pwin2,\n             score = score, \n             value = tmp[1, ]$value)\n}\n\npicks_oc_mult = function(NUM_WEEKS = 12, START_WEEK = 4) {\n  \n  for (i in START_WEEK:NUM_WEEKS) {\n    \n    weeks = seq(START_WEEK, NUM_WEEKS, 1)[!seq(START_WEEK, NUM_WEEKS, 1) %in% picks$week]\n    rankings = lapply(weeks, function(x) delta_mult(x, picks)) |> bind_rows()\n    pick = rankings[rank(-rankings$score) == 1, ]\n    picks = rbind(picks, pick)\n  }\n  \n  arrange(picks, week)\n  \n}\n\npicks = data.frame()\noc_mult = picks_oc_mult(NUM_WEEKS = NUM_WEEKS, START_WEEK = START_WEEK)\n\n\n# Greedy Pick with 2 teams\ngreedy_picks = data.frame()\nfor(week_num in unique(pool$week)) {\n  tmp = pool[week == week_num & \n               !team1 %in% greedy_picks$team1 & \n               !team2 %in% greedy_picks$team2, ]\n  tmp = arrange(tmp, -value)\n  pick = tmp[1, ]\n  greedy_picks = rbind(greedy_picks, pick)\n}\n\nplot = rbind(oc_mult |> select(-score) |> mutate(label = \"OC\"), \n      greedy_picks |> select(week, pick1 = team1, pick2 = team2, pwin1, pwin2, value) |> mutate(label = \"Greedy\"))\n\nplot |> \n  group_by(week) |>\n  mutate(d = lag(value) - value, # compute difference between pick probs\n         y_pos = (lag(value) + value)/2,  # compute the positioning to be in the middle of picks\n         y_label = ifelse(d == 0, \"\", paste0(round(d * 100, 1), \"%\")), \n         pick = sprintf(\"{%s, %s}\", pick1, pick2), \n         pick = ifelse(y_label == \"\" & !is.na(y_label), \"\", pick)) |>\n  ggplot(aes(x = week, y = value, color = label)) + \n  geom_line(aes(group = week), color=\"#e3e2e1\", size = 2, alpha = 0.7) + \n  geom_point(size = 3) + \n  geom_text(aes(x = week, y = y_pos, label = y_label), color = \"#414a4c\", nudge_x = 0.4) +\n  ggrepel::geom_text_repel(aes(x = week, y = value, label = pick), nudge_x = 0.5, color = \"#414a4c\", direction = \"y\", size = 3) +\n  scale_color_viridis_d(option = color_scheme) + \n  scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) + \n  scale_y_continuous(labels = scales::percent_format(), n.breaks = 10) +\n  labs(title = \"Week-by-Week Multi-Entry Model Comparisions\", \n       subtitle = \"Showing the change in probabilities for Multi-Entry OC and Greedy Algorithms\",\n       caption = \"Differences are interepreted as the likelihood of getting through the week that is lost by following the Greedy model.\",\n       x = \"Week Number\", \n       y = \"Probability at least one pick loses\", \n       color = \"Model\") + \n  theme(legend.position=c(.085,.85), \n        legend.background = element_blank())\n\n# plot |> \n#   group_by(label) |> \n#   summarise(mean = mean(value),\n#             sd = sd(value)) |> \n#   kbl(caption = \"Average Likelihood of Moving on per Week\", \n#       digits = 2) |>\n#   kable_paper(full_width = F)\n#   \n\n```\n\n<!-- ## Team Ownership -->\n\n<!-- Since we know who has already been selected, we can attempt to model the decision process by our competitors. Teams that have been picked by many people are advantageous to select, as we know others will not also be able to pick these teams. This means we can remove ourselves from the clusters of picks, and avoid any upsets that lead to mass eliminations. -->\n\n<!-- The below chart shows the win probabilities per team along with the share of players in the competition who have already selected that team. As the weeks progress, we will use this information to further influence our picks.  -->\n\n```{r}\nss = \"https://docs.google.com/spreadsheets/d/1VlUyf967K2zdV26zMV5zaF5xaV3z_Sbh8mRurEj0D4E/edit#gid=0\"\nownership = googlesheets4::read_sheet(ss)\n\n# ownership = read.csv(\"ownership.csv\")\n\n# reshape and remove players who did not submit a pick in the latest week - i.e. are eliminated\nown = ownership |>\n  pivot_longer(cols = -c(\"Player\"), names_to = \"week\", values_to = \"pick\") |> \n  filter(!is.na(pick)) |>\n  group_by(Player) |> \n  mutate(week = as.numeric(week), \n         max_week = max(week)) |> \n  ungroup()\n  \n# compute the proportion of people who have picked each team\nteam_ownership = df |> \n  group_by(team) |> \n  summarise(share = sum(team == own$pick, na.rm=T) / length(unique(own$Player))) # divide times picked by remaining players\n\nOWN_THRESH = 0.35\n\n# df |> \n#   left_join(team_ownership, by = \"team\") |> \n#   mutate(label = case_when(share >= OWN_THRESH ~ team, \n#                            TRUE ~ \"\")) |>\n#   filter(week %in% c(START_WEEK:NUM_WEEKS)) |>\n#   ggplot(aes(x = week, y = pwin, size = -share)) + \n#   geom_point(alpha = 0.6) + \n#   geom_text(aes(label = label), nudge_x = 0.3, size = 3) + \n#   labs(title = \"Team Win Probabilities by Team Ownership\", \n#        subtitle = \"The smaller the dot, the greater the number of players who can no longer pick that game\", \n#        x = \"Week Number\", \n#        y = \"Win Probability\", \n#        color = \"Ownership\", \n#        caption = sprintf(\"Names showing for teams with a greater than %s%% ownership\", OWN_THRESH*100)) + \n#   scale_color_viridis_c(labels = scales::percent_format(), option = color_scheme) + \n#   scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) +\n#   scale_y_continuous(labels = scales::percent_format()) +\n#   theme(legend.position = \"none\")\n\n\n```\n\n## Results\n\nBelow are picks per entry, where picks which won their game are shown with red text. Once a player is removed, they no longer show up on the plot, and players are sorted in ascending order in terms of their average win probability - players higher in the plot have had lower win probabilities up to the shown week.\n\n```{r}\nown |> \n  select(Player, week, pick) |>\n  left_join(plot_data |> select(week, pick = team, pwin), \n            by = c(\"week\", \"pick\")) |> \n  left_join(eliminations |> mutate(upset = 1), \n            by = c(\"week\", \"pick\")) |> \n  group_by(Player) |> \n  mutate(label = pick, \n         max_week = max(week, na.rm = TRUE),\n         rank = mean(1-pwin, na.rm=TRUE) + max_week) |>\n  ungroup() |>\n  mutate(Player = reorder(Player, rank)) |> \n  ggplot(aes(x = week, y = Player, fill = pwin, label = label)) + \n  geom_tile(color = \"white\") + \n  geom_text(aes(label = label, color = is.na(upset)), size = 2.5) + \n  scale_color_manual(values = c(\"darkred\", \"white\")) +\n  scale_fill_viridis_c(option = color_scheme, label = scales::percent_format()) + \n  scale_x_continuous(breaks = 1:10, expand = c(0, 0), limits = c(0.5, 10)) + \n  theme(legend.position = c(.9,.75), \n        legend.background = element_blank()) +\n  labs(title = \"Weekly Picks, by win probabilities\", \n       subtitle = \"Players sorted by average win probability, upsets marked in red\",\n       x = \"Week\", \n       y = \"Pool Entries\", \n       fill = \"Win Probability\") + \n  guides(color = FALSE)\n```\n\nI followed the Opportunity Cost model recommendations for most of my picks. I swapped out the recommended New England in Week 4 for the New York Jets as none of the remaining players in the pool had yet to choose NE, and it is beneficial to separate yourself from the group given how often we see upsets. Unfortunately for me, it was the NYJ and not NE game that resulted in an upset.\n\nAnd just like that, that is a wrap for the 2022 Losers Pool! Big congrats to Drew2, Billy and DM who chose to split the pot following Week 7. Hopefully we can improve on our algorithms and selection process come the 2023 season. I think there is some value to be found in optimizing across multiple entries, as well as being able to shift from minimizing the risk of being eliminated to maximizing the expected value of a set of picks conditional on who the remaining players have left in the pool.\n\n<!-- We barely squeak through Week three with a last-minute comeback by the Minnesota Vikings (Hutch1 above) to edge out the Lions. We lose one of our entries however, we aren't that worse off as we went out with seven of the remaining 25 teams picking Jacksonville. This also means we are back to optimizing in terms of the single-entry method, which is a bit of a bummer. I think there is more improvements and exploration that can be done under the multi-entry model. -->\n\n<!-- ## Weekly Picks  -->\n\n<!-- With only 11 players remaining, we can consider reducing the range of weeks we want to optimize over, or at least should compare the outcomes under different week profiles.  -->\n\n<!-- ```{r} -->\n\n<!-- # read in data & remove past picks  -->\n\n<!-- df = read_data(path) |>  -->\n\n<!--   filter(!team %in% c(\"PIT\", \"CHI\", \"DET\")) -->\n\n<!-- picks_oc_mult = function(NUM_WEEKS = 12, START_WEEK = 4) { -->\n\n<!--   for (i in START_WEEK:NUM_WEEKS) { -->\n\n<!--     weeks = seq(START_WEEK, NUM_WEEKS, 1)[!seq(START_WEEK, NUM_WEEKS, 1) %in% picks$week] -->\n\n<!--     rankings = lapply(weeks, function(x) delta_mult(x, picks)) |> bind_rows() -->\n\n<!--     pick = rankings[rank(-rankings$score) == 1, ] -->\n\n<!--     picks = rbind(picks, pick) -->\n\n<!--   } -->\n\n<!--   arrange(picks, week) -->\n\n<!-- } -->\n\n<!-- profiles = data.frame() -->\n\n<!-- for(i in 8:12) { -->\n\n<!--   picks = data.frame() -->\n\n<!--   out = picks_by_oc(START_WEEK = 4, NUM_WEEKS = i) -->\n\n<!--   out$label = sprintf(\"Profile 4-%s\", i) -->\n\n<!--   profiles = rbind(profiles, out) -->\n\n<!-- } -->\n\n<!-- profiles |>  -->\n\n<!--   rename(Week = week) |>  -->\n\n<!--   tidyr::pivot_wider(id_cols = c(\"Week\"), names_from = \"label\", values_from = \"pick\", values_fill = \"\") |>  -->\n\n<!--   kbl(align = \"c\") |>  -->\n\n<!--   kable_paper(\"striped\") |>  -->\n\n<!--   add_header_above(c(\" \"=1, \"Week Profile\" = 5)) -->\n\n<!-- ``` -->\n\n<!-- There is no change in the optimal picks when optimizing from Week 8 until Week 11. Therefore, we do not need to worry about optimizing too far ahead this week.  -->\n\n<!-- Another point worth mentioning is that noone has picked NE in the pool yet, which means it is likely some players will select them, and it could be advantagous to pick the next best team this week. Below are the remaining teams I can select in Week 4, as well as their associated ownership by others remaining in the pool.  -->\n\n<!-- ```{r} -->\n\n<!-- # df |> -->\n\n<!-- #   filter(week == 4, -->\n\n<!-- #          !team %in% c(\"PIT\", \"CHI\", \"DET\")) |> -->\n\n<!-- #   arrange(pwin) |> -->\n\n<!-- #   select(team, pwin) |> -->\n\n<!-- #   left_join(team_ownership, by = \"team\") |> -->\n\n<!-- #   kbl(caption = \"Possible Picks in Week 4 and Ownership\", -->\n\n<!-- #       digits = 2) |> -->\n\n<!-- #   kable_paper(\"striped\") |> -->\n\n<!-- #   scroll_box(height = \"250px\") -->\n\n<!-- # correct ownership for eliminations -->\n\n<!-- own3 = own |>  -->\n\n<!--   filter(week < 4) -->\n\n<!-- team_ownership = own3 |>  -->\n\n<!--   mutate(eliminated = (week == 3 & pick %in% c(\"IND\", \"JAX\", \"DAL\"))) |>  -->\n\n<!--   group_by(Player) |>  -->\n\n<!--   mutate(drop = max(eliminated),  -->\n\n<!--          max_week = max(week)) |>  -->\n\n<!--   filter(drop == 0,  -->\n\n<!--          max_week == 3) |>  -->\n\n<!--   ungroup() |>  -->\n\n<!--   group_by(team = pick) |>  -->\n\n<!--   summarise(share = n() / 11) -->\n\n<!-- df |>  -->\n\n<!--   filter(week == 4,  -->\n\n<!--          !team %in% c(\"PIT\", \"CHI\", \"DET\")) |>  -->\n\n<!--   arrange(pwin) |>  -->\n\n<!--   select(team, pwin) |>  -->\n\n<!--   left_join(team_ownership, by = \"team\") |>  -->\n\n<!--   mutate(share = ifelse(is.na(share), 0, share)) |> -->\n\n<!--   ggplot(aes(x = share, y = pwin)) +  -->\n\n<!--   geom_point() +  -->\n\n<!--   ggrepel::geom_text_repel(aes(label = team), nudge_x = 0.015) +  -->\n\n<!--   scale_x_continuous(labels = scales::percent_format()) +  -->\n\n<!--   scale_y_continuous(labels = scales::percent_format()) +  -->\n\n<!--   labs(title = \"Comparing Win Probability with Proportion Already Selected\",  -->\n\n<!--        subtitle = \"Picks through Week 3\", -->\n\n<!--        x = \"Proportion previously picked\",  -->\n\n<!--        y = \"Win Probability\") -->\n\n<!-- ``` -->\n\n<!-- Our OC algorithm recommends to take NE, however it is naive to the picks already made by others in the pool. When we look at the ownership proportions, we can see that out of the remaining 11 players, 7 have already picked NYJ, and that none have picked JAX or NE. Additionally, we can see there is a large jump from JAX to NO, so we can expect at most 3 picks on NYJ, and the remaining 7 split between NE and JAX. Given last weeks JAX upset, I suspect less people will take JAX, and will instead hop on NE. Therefore, it is a matter of taking NYJ who are facing PIT, or I go with JAX who are facing the top PHI. I'm torn between the two, however think I should give myself the chance at winning if everyone splits on NE and JAX with the unlikely 8% chance. This comes at the cost of having greater risk in Week 6 as I'll have to go with DAL, but the increased risk there is likely worth avoiding another wave of possible eliminations. -->\n\n<!-- **Thursday update**  -->\n\n<!-- ```{r} -->\n\n<!-- own |>  -->\n\n<!--   ungroup() |>  -->\n\n<!--   filter(week == 4) |>  -->\n\n<!--   select(-c(max_week, week)) |>  -->\n\n<!--   group_by(pick) |>  -->\n\n<!--   summarise(n = n(), Players = paste(Player, collapse = \", \")) |>  -->\n\n<!--   arrange(desc(n)) |>  -->\n\n<!--   kbl(col.names = c(\"Pick\", \"N\", \"Entries\"), caption = \"Week 4 Picks\") |>  -->\n\n<!--   kable_paper(full_width = F) -->\n\n<!-- ``` -->\n\n<!-- Our predictions were nearly correct, there were a large share (7 of 11) players who took NE, only 1 took JAX, and the remaining two took BAL and MIA. Two of the non-NE picks came from players who had multiple entries into the competition, and had already taken NE.  -->\n\n<!-- By deviating from this group, we are in a fantastic position, as we gave up ~2.5% in order to move away from the crowd.  -->\n\n<!-- Now there is a roughly 20% chance we see a NE win, and a NYJ loss moving us onto next week with at most 3 other competitors. Fingers crossed, and onto week 5!  -->\n","srcMarkdownNoYaml":"\n\n<!-- <style type=\"text/css\"> -->\n\n<!--    .main-container {max-width: 50%;} -->\n\n<!--    .row {display: flex;} -->\n\n<!--    .column {flex: 50%;} -->\n\n<!-- </style> -->\n\n<!-- {{ $readTime := mul (div (countwords .Content) 220.0) 60 }} -->\n\n<!-- {{ $minutes := math.Floor (div $readTime 60) }} -->\n\n<!-- {{ $seconds := mod $readTime 60 }} -->\n\n<!-- <p>Reading time: {{ $minutes }} {{ cond (eq $minutes 1) \"minute\" \"minutes\" }} and -->\n\n<!--     {{ $seconds }} {{ cond (eq $seconds 1) \"second\" \"seconds\" }}.</p> -->\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, \n                      warning = FALSE, \n                      message = FALSE, \n                      echo = FALSE, \n                      fig.align = \"center\", \n                      out.width=\"80%\")\n\npacman::p_load(googlesheets4, ggplot2, dplyr, data.table, tidyr, kableExtra)\n\ntheme_set(\n  theme_bw() + \n  theme(\n    panel.grid.major = element_blank(), \n    # axis.ticks.y = element_blank(),\n    plot.title=element_text(size = 16, face=\"bold\"),\n    plot.title.position = \"plot\",\n    plot.subtitle=element_text(face=\"italic\", size=12, margin=margin(b=12)),\n    plot.caption=element_text(size=8, margin=margin(t=8), color=\"#7a7d7e\"), \n    legend.position = \"bottom\"\n    )\n)\n\ncumprob = function(picks, inc_weeks = FALSE){\n  purrr::accumulate((1-picks$pwin), function(x, y)  x * y)\n}\n\npath = \"https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv\"\n\n\n# Parameters\nSTART_WEEK = 3\nNUM_WEEKS = 12\n\neliminations = data.frame(week = c(    1,     1,     1,     1,     2,     2,     3,     3,     3,     4,      6,     6,     7,     7), \n                          pick = c(\"PIT\", \"NYG\", \"SEA\", \"CLE\", \"DAL\", \"MIA\", \"IND\", \"JAX\", \"DAL\", \"NYJ\",  \"NYJ\", \"ATL\", \"CAR\", \"CLE\"))\n\ncolor_scheme = \"D\" # for scale_virdis\n\npast_picks = data.frame(week = c(1, 2), \n                   team1 = c(\"PIT\", \"CHI\"),\n                   team2 = c(\"PIT\", \"CHI\"))\n```\n\nComing out of of Labour Day weekend only means one thing, it is time again for the annual NFL Losers Pool competition. This is the second time I am writing about this type of competition. You can see my blog post about trying to draft an optimal lineup here: [2021 NFL Losers Pool](https://www.jordanhutchings.com/blog/2021-11-19-nfl-fantasy-losers-pool/).\n\nBelow are the rules for our 2022 contest.\n\n## Losers Pool Rules\n\n1.  You must pick exactly one team per week to lose their game.\n2.  You cannot pick the same team more than once per season.\n3.  If your team wins their game, you are eliminated.\n4.  Rebuys back into the competition are allowed for Weeks 1 and 2.\n5.  You may enter up to three sets of picks.\n\n## Pick Optimization\n\nThe objective of this competition is to outlast the other competitors in the pool. Specifically, this means avoiding elimination and being the remaining player in the pool. The second point is worth noting because we will shift our strategy from simply minimizing the risk of our picks losing, to maximizing the likelihood that our picks move on relative to the picks of others in the pool. A quick foreshadowing - this will involve using *team ownership* to trade-off probability of making it to the next week for increasing our expected value in the competition.\n\nThere are a total of 32 teams to choose from, and we can expect the pool to run for roughly 10 weeks - going off of last years competition. This is a large number of potential combinations of teams to select in each week. In fact for 10 weeks, it is $32 \\times 31 \\times ... \\times 22$ which is roughly 234 trillion combinations (I'm not including teams with bye weeks but you get the idea, the space of possible picks is very large).\n\nFortunately, we can be smart about our optimization, and conditional on game forecasts, reach the global optimum without much computation work. I use two different algorithms to compare pick schedules; what I call the Opportunity Cost Model and Greedy Model. The Greedy Model will out preform the Opportunity Cost model in the short run, but eventually the Opportunity Cost model will pass the Greedy Model in future weeks.\n\n1.  **Opportunity Cost Model** - picking the lowest win probability team in a given week conditional on it having the largest distance to the second lowest win probability that same week.\n\n2.  **Greedy Model** - Picking the team with the lowest win probability in the first week, then the second, and so on...\n\n**Opportunity Cost Model Algorithm**\n\n1.  Step 1: Compute the difference between the least and second least likely teams to win in each week for each team and week in the pool.\n2.  Step 2: Pick the team & week combination with the largest difference between the least and second least likely teams.\n3.  Step 3: Remove the week and team combination from the pool and repeat Steps 1 & 2 until all weeks are filled.\n\n![](oc-anim.gif) <!--Speed up the gif speed, change dimensions in the r file to make fill the page --> <!-- There is some weird error where teams are disappearing in between stages -->\n\n**Greedy Model Algorithm**\n\n1.  Step 1: Start at the earliest week we wish to optimize over.\n2.  Step 2: Pick the team with the lowest probability of winning, and remove this team from the candidate pool.\n3.  Step 3: Move on to the next week, and repeat Steps 2 and 3 until we reach the terminal week.\n\n![](naive-anim.gif)\n\n## Making Picks\n\nLets put the above algorithms to action. Like last year, I am using the [FiveThirtyEight NFL Projections](https://projects.fivethirtyeight.com/2022-nfl-predictions/) to estimate each teams likelihood of winning their game. These ratings are based off of each teams computed ELO score, with some additional adjustments - read about their methodology [here](https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/).\n\nWe can see that there are some clear weeks below with drastic underdogs, and each week after Week 1 contains at least one game with a win probability less than 25%.\n\n```{r}\n# tidy data to be: week | team | prob win\ndata = fread(path)\ndata[, week := floor(as.numeric(difftime(date + 1, \"2022-09-08\", units=\"days\")) / 7) + 1]\ndata = data[, .(week, team1, team2, qbelo_prob1, qbelo_prob2)]\nteam1 = data[, .(week, team1, qbelo_prob1)]\nteam2 = data[, .(week, team2, qbelo_prob2)]\nplot_data = rbind(team1 |> select(week, team = team1, pwin = qbelo_prob1), \n                  team2 |> select(week, team = team2, pwin = qbelo_prob2))\n\nplot_data |> \n  group_by(team) |>\n  mutate(avg_p = mean(pwin), \n         tag = ifelse(pwin < 0.25, \"X\", \"\")) |> \n  ungroup() |> \n  mutate(team = reorder(team, avg_p)) |> \n  ggplot(aes(x = week, y = team, fill = pwin)) + \n  geom_tile() + \n  geom_text(aes(label = tag, x = week, y = team), color = \"white\") + \n  theme(legend.position = \"right\") + \n  scale_fill_viridis_c(\"Win Probability\", labels = scales::percent_format(), option = color_scheme) + \n  labs(title = \"Heatmap of Win Probabilities - By Team and Week\", \n       subtitle = \"White crosses represent win probabilities less than 25%\",\n       caption = \"QB ELO probabilities used taken from FiveThirtyEight NFP 2022 Predictions.\\nRows are sorted by the average win probability across all games.\",\n       x = \"Week Number\", \n       y = \"\") + \n  scale_x_continuous(expand = c(0, 0), breaks = 1:18)\n```\n\nI choose to run the above two algorithms starting in Week 3. Since we can rebuy back into the competition in Weeks 1 and 2, we do not want to take a valuable pick from our elimination weeks. Therefore, I make my set of picks on weeks 3 through 10, then pick Week 1 and 2 after removing the Weeks 3 - 10 picks, this ended up being the Pittsburgh Steelers and Chicago Bears.\n\nThe pick schedules using both algorithms are shown below. Notice the trade off of early week win probabilities for later risk savings.\n\n```{r, compare-algos}\n# Throw downloading data into a tryCatch so we can use a local copy w/o internet\nread_data = function(path, init_week = \"2022-09-08\") {\n  cols = c(\"date\", \"season\", \"team1\", \"team2\", \"qbelo_prob1\", \"qbelo_prob2\")\n  dt = fread(path, select = cols)\n  dt |> \n    mutate(pwin = pmin(qbelo_prob1, qbelo_prob2), \n           team = case_when(\n             qbelo_prob1 < qbelo_prob2 ~ team1, \n             qbelo_prob1 >= qbelo_prob2 ~ team2,\n             TRUE ~ \"ERROR\"), \n           week = floor(as.numeric(difftime(date + 1, init_week, units=\"days\")) / 7) + 1) |> \n    select(-c(team1, team2, qbelo_prob1, qbelo_prob2))}\n  \n\npath = \"https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv\"\ndf = read_data(path)\n\n# use previously downloaded data to keep the elo chart consistent\n# df = fread(\"elo_predictions.csv\")\n\n# Opportunity Cost Model ----\ndelta = function(week_num, picks) {\n  \n  tmp = arrange(df[week == week_num & !team %in% picks$pick], pwin) # sort and filter for a given week\n  score = tmp[2, ]$pwin - tmp[1, ]$pwin # compute oc of best pick\n  \n  data.frame(\n    pick = tmp[1]$team,\n    score = score, \n    week = week_num,\n    pwin = tmp[1]$pwin\n  )\n    \n}\n\npicks_by_oc = function(NUM_WEEKS = 12, START_WEEK = 3) {\n  \n  picks = data.frame()\n  \n  for(i in START_WEEK:NUM_WEEKS) {\n    weeks = seq(START_WEEK, NUM_WEEKS, 1)[!seq(START_WEEK, NUM_WEEKS, 1) %in% picks$week]\n    rankings = lapply(weeks, function(x) delta(x, picks)) |> bind_rows()\n    pick = rankings[rank(-rankings$score) == 1, ]\n    picks = rbind(picks, pick)\n  }\n  \n  arrange(picks, week)\n}\n\npicks_oc = picks_by_oc(NUM_WEEKS, START_WEEK)\npicks_oc$cumprob = cumprob(picks_oc)\n\n# Greedy Model ----\npicks_by_naive = function(NUM_WEEKS = 12, START_WEEK = 3) {\n  \n  picks_naive = data.frame()\n  \n  for(i in START_WEEK:NUM_WEEKS) {\n  \n    tmp = arrange(df[week == i & !team %in% picks_naive$pick], pwin)\n    \n    pick = data.frame(\n      pick = tmp[1]$team,\n      week = i,\n      pwin = tmp[1]$pwin\n    )\n    \n    picks_naive = rbind(picks_naive, pick)\n    \n  }\n  arrange(picks_naive, week)\n}\n\n# compute the likelihood of reaching the next week\npicks_naive = picks_by_naive(NUM_WEEKS, START_WEEK)\npicks_naive$cumprob = cumprob(picks_naive)\n\n# Join models ----\npicks = rbind(picks_oc |> select(-score) |> mutate(label = \"OC\"), \n              picks_naive |> mutate(label = \"Greedy\"))\n\n# Plot results \npicks |> \n  group_by(week) |>\n  mutate(d = lag(pwin) - pwin, # compute difference between pick probs\n         y_pos = (lag(pwin) + pwin)/2,  # compute the positioning to be in the middle of picks\n         y_label = ifelse(d == 0, \"\", paste0(round(d * 100, 1), \"%\")), \n         pick = ifelse(y_label == \"\" & !is.na(y_label), \"\", pick)) |> # only show label for one of two identical picks\n  ggplot(aes(x = week, y = pwin, color = label, label = y_label)) + \n  geom_line(aes(group = week), color=\"#e3e2e1\", size = 2, alpha = 0.7) + \n  geom_point(size = 3) + \n  geom_text(aes(x = week, y = y_pos), color = \"#414a4c\", nudge_x = 0.4) + \n  ggrepel::geom_text_repel(aes(x = week, y = pwin, label = pick), nudge_x = 0.3, color = \"#414a4c\", direction = \"y\") + \n  scale_color_viridis_d(option = color_scheme) + \n  scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) + \n  scale_y_continuous(labels = scales::percent_format(), n.breaks = 10) +\n  labs(title = \"Week-by-Week Win Probabilities across Models\", \n       subtitle = \"Showing the change in probabilities for each approach\",\n       caption = \"Differences are interepreted as the additional risk taken on by selecting the OC model.\\nData is updated weekly, and so predictions in plot are subject to change.\",\n       x = \"Week Number\", \n       y = \"Win Probability\", \n       color = \"Model\") + \n  theme(legend.position=c(.105,.15), \n        legend.background = element_blank())\n```\n\nWe can compare the performance of both algorithms by comparing the likelihoods of reaching a given week for both models. The likelihood we move on from a given week $w$ is equal to the probability $P(W\\leq w)$ where,\n\n```{=tex}\n\\begin{align*}\nP(W\\leq w) &= \\Pi_{w=3}^{12} p_{i, w}\\cdot x_{i, w} \\\\ \n\\text{Subject to } & \\sum_i x_{i, w} = 1 \\\\\n& \\sum_w x_{i, w} \\leq 1\n\\end{align*}\n```\nWhich is the likelihood a given schedule of picks reaches week 10 subject to being able to pick only one team per week, and picking any given team at most once.\n\n<!-- $$P(W\\leq w) = \\Pi_{t=3}^{10} p_{i, w}\\cdot x_{i, w}$$ where $p_{i,w}$ is the likelihood the $i^{th}$ selected team loses their game in week $w$.  -->\n\n```{r, cumprob-plot, eval=FALSE}\n\n# data changed, so using screengrab of past version of the plot\npicks |> \n  ggplot(aes(x = week, y = cumprob, color = label)) + \n  geom_point() + \n  geom_line() + \n  scale_color_viridis_d(option = color_scheme) + \n  scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) + \n  scale_y_continuous(labels = scales::percent_format(), n.breaks = 10) +\n  labs(title = \"Week-by-Week Win Probabilities across Models\", \n       subtitle = \"Showing the change in probabilities for each approach\",\n       caption = \"Differences are interepreted as the additional risk taken on by selecting the OC model.\",\n       x = \"Week Number, w\", \n       y = \"P(W <= w)\", \n       color = \"Model\") + \n  theme(legend.position=c(.935,.85), \n        legend.background = element_blank())\n```\n\n![](cumprob-plot-1.png)\n\n## Optimal Decisions under Multiple Entries\n\nOne interesting aspect of the Losers Pool is that we are able to submit multiple submissions into the competition. The above analysis works for the Single-Entry case, however things become more complex in the Multiple-Entry case. When dealing with multiple entries, I move from minimizing the cost of being eliminated in any given week, to minimizing the likelihood all of the entries are eliminated in a given week. We can represent each combination of an N-team tuple as a possible pick in a given week, and calculate the probability of at least one team moving onto the next week from a tuple of N picks. Given we have two entries in the competition, this is equal to $1 - (p_{i, w} \\cdot x_{i, w})(p_{j, w} \\cdot x_{j, w})$.\n\nBy computing the above likelihoods of each tuple moving onto the following week, we can then run the Opportunity Cost model on the set of picks, taking the pick with the largest difference between the best and second best pick across all weeks we are considering.\n\n<!-- $$\\mathrm{P(\\text{At least one team loses})}_{i\\in \\mathcal I, w} = 1 - \\Pi_{i \\in \\mathcal I, w}(p_{i, w}\\cdot x_{i, w})$$ -->\n\n<!-- Where $\\mathcal I$ is the set of teams considered in the tuple for week $w$. Using the above notation, our objective function becomes:  -->\n\n<!-- \\begin{align*} -->\n\n<!-- & \\max_{}\\Pi_{w=3}^{10} 1 - \\Pi_{i \\in \\mathcal I, w}(p_{i, w}\\cdot x_{i, w}) -->\n\n<!-- \\text{Subject to} &  -->\n\n<!-- \\end{align*} -->\n\n```{r, multi-entries}\n\n# make data of permutations of combinations\ndf = df[, .(week, team, pwin)]\n\ncross_data = data.frame()\nsetDT(cross_data)\n\nfor(w in unique(df$week)) {\n\n  tmp = df[week == w, ]\n  \n  for(row in 1:nrow(tmp)) {\n    team1 = tmp[row, ]\n    out = merge(tmp, team1, by = \"week\", all.x = TRUE, suffixes = c(\"1\", \"2\"))\n    cross_data = rbind(cross_data, out)\n  }\n  \n}\n\ncross_data[team1 != team2, value := (1 - pwin1 * pwin2)]\ncross_data[team1 == team2, value := (1 - pwin1)]\n\n# plot\np = cross_data |> \n  filter(week %in% START_WEEK:NUM_WEEKS) |> \n  mutate(week_label = paste(\"Week\", week), \n         week_label = reorder(week_label, rank(week))) |> \n  ggplot(aes(x = team1, y = team2, fill = value)) + \n  geom_tile() + \n  scale_fill_viridis_c(label = scales::percent_format(), direction = -1) + \n  theme(axis.text.x = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks = element_blank()) + \n  facet_wrap(.~week_label, nrow = 2, scales=\"free\") + \n  labs(title = \"Likelihood of moving on through the week\", \n       subtitle = \"Weeks shown as facets - the darker the better\", \n       fill = \"Prob at least one team loses\", \n       caption = \"Team labels removed for each week simply to demonstrate how to visualize the comparisons\", \n       x = \"\", \n       y = \"\") + \n  theme(legend.position = \"none\")\n\n# extra steps to center plotly\npp <- plotly::ggplotly(p)    # As before\nhtmltools::div( pp, align=\"center\" )  # Result is now an HTML object\n\n # plotly drops the subtitle, and caption\n```\n\n*The above plot has its axis removed, however is interactive. By hovering each cell you can see the pick tuple as well as the likelihood one of the two teams moves on. The darker the cell, the greater the likelihood of at least one team losing their game that week.*\n\nSome observations:\n\n-   It is almost always best to diversify your picks. Despite Atlanta having a low win rate in Week 5, combinations of picking Atlanta and another team still dominate picking Atlanta.\n-   The matrix is symmetric, however ordering of picks matters as picking a team in the first spot can still allow for the same team to be picked in the second spot. i.e. (DET, JAX) and (JAX, DET) are valid in consecutive weeks.\n\nAs above, we can compare the performance of the OC model with the Greedy Model in the Multi-Entry case. The below plot is in terms of the likelihood of moving onto the following week, and so a higher is better. As with the Single-Entry case, we can see the OC model trading off some early likelihood for greater future likelihoods of having at least one team move onto the next week.\n\n```{r}\n# cross_data |> \n#   filter(week %in% START_WEEK:NUM_WEEKS) |>\n#   mutate(label = paste(team1, team2)) |> \n#   ggplot(aes(x = week, y = value)) + \n#   geom_point(alpha = 0.1) + \n#   scale_y_continuous(labels = scales::percent_format()) + \n#   scale_x_continuous(breaks = 3:10) + \n#   labs(title = \"Likelihood of moving on from a given week\", \n#        subtitle = \"Each point represents a set of two possible picks in a given week\", \n#        x = \"Week Number\", \n#        y = \"Pr(At Least One Submission Moving on)\") \n\n\n# remove prev picked teams or weeks out of samples\npool = cross_data[week %in% START_WEEK:NUM_WEEKS &\n  !week %in% past_picks$week &\n  !team1 %in% past_picks$team1 &\n  !team2 %in% past_picks$team2, ]\n\n# compute the distance between the best and second best pick per week\ndelta_mult = function(week_num, picks) {\n  \n  tmp = arrange(pool[week == week_num & !team1 %in% picks$pick1 & !team2 %in% picks$pick2], -value)\n  # logic to not count the value below if they're the same - as we have the same game with team1 and team2 flipped\n  if (tmp[1, ]$value == tmp[2, ]$value) {\n    score = tmp[1, ]$value - tmp[3, ]$value\n  } else {\n    score = tmp[1, ]$value - tmp[2, ]$value\n  }\n  \n  data.frame(week = week_num,\n             pick1 = tmp[1, ]$team1, \n             pick2 = tmp[1, ]$team2, \n             pwin1 = tmp[1, ]$pwin1, \n             pwin2 = tmp[1, ]$pwin2,\n             score = score, \n             value = tmp[1, ]$value)\n}\n\npicks_oc_mult = function(NUM_WEEKS = 12, START_WEEK = 4) {\n  \n  for (i in START_WEEK:NUM_WEEKS) {\n    \n    weeks = seq(START_WEEK, NUM_WEEKS, 1)[!seq(START_WEEK, NUM_WEEKS, 1) %in% picks$week]\n    rankings = lapply(weeks, function(x) delta_mult(x, picks)) |> bind_rows()\n    pick = rankings[rank(-rankings$score) == 1, ]\n    picks = rbind(picks, pick)\n  }\n  \n  arrange(picks, week)\n  \n}\n\npicks = data.frame()\noc_mult = picks_oc_mult(NUM_WEEKS = NUM_WEEKS, START_WEEK = START_WEEK)\n\n\n# Greedy Pick with 2 teams\ngreedy_picks = data.frame()\nfor(week_num in unique(pool$week)) {\n  tmp = pool[week == week_num & \n               !team1 %in% greedy_picks$team1 & \n               !team2 %in% greedy_picks$team2, ]\n  tmp = arrange(tmp, -value)\n  pick = tmp[1, ]\n  greedy_picks = rbind(greedy_picks, pick)\n}\n\nplot = rbind(oc_mult |> select(-score) |> mutate(label = \"OC\"), \n      greedy_picks |> select(week, pick1 = team1, pick2 = team2, pwin1, pwin2, value) |> mutate(label = \"Greedy\"))\n\nplot |> \n  group_by(week) |>\n  mutate(d = lag(value) - value, # compute difference between pick probs\n         y_pos = (lag(value) + value)/2,  # compute the positioning to be in the middle of picks\n         y_label = ifelse(d == 0, \"\", paste0(round(d * 100, 1), \"%\")), \n         pick = sprintf(\"{%s, %s}\", pick1, pick2), \n         pick = ifelse(y_label == \"\" & !is.na(y_label), \"\", pick)) |>\n  ggplot(aes(x = week, y = value, color = label)) + \n  geom_line(aes(group = week), color=\"#e3e2e1\", size = 2, alpha = 0.7) + \n  geom_point(size = 3) + \n  geom_text(aes(x = week, y = y_pos, label = y_label), color = \"#414a4c\", nudge_x = 0.4) +\n  ggrepel::geom_text_repel(aes(x = week, y = value, label = pick), nudge_x = 0.5, color = \"#414a4c\", direction = \"y\", size = 3) +\n  scale_color_viridis_d(option = color_scheme) + \n  scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) + \n  scale_y_continuous(labels = scales::percent_format(), n.breaks = 10) +\n  labs(title = \"Week-by-Week Multi-Entry Model Comparisions\", \n       subtitle = \"Showing the change in probabilities for Multi-Entry OC and Greedy Algorithms\",\n       caption = \"Differences are interepreted as the likelihood of getting through the week that is lost by following the Greedy model.\",\n       x = \"Week Number\", \n       y = \"Probability at least one pick loses\", \n       color = \"Model\") + \n  theme(legend.position=c(.085,.85), \n        legend.background = element_blank())\n\n# plot |> \n#   group_by(label) |> \n#   summarise(mean = mean(value),\n#             sd = sd(value)) |> \n#   kbl(caption = \"Average Likelihood of Moving on per Week\", \n#       digits = 2) |>\n#   kable_paper(full_width = F)\n#   \n\n```\n\n<!-- ## Team Ownership -->\n\n<!-- Since we know who has already been selected, we can attempt to model the decision process by our competitors. Teams that have been picked by many people are advantageous to select, as we know others will not also be able to pick these teams. This means we can remove ourselves from the clusters of picks, and avoid any upsets that lead to mass eliminations. -->\n\n<!-- The below chart shows the win probabilities per team along with the share of players in the competition who have already selected that team. As the weeks progress, we will use this information to further influence our picks.  -->\n\n```{r}\nss = \"https://docs.google.com/spreadsheets/d/1VlUyf967K2zdV26zMV5zaF5xaV3z_Sbh8mRurEj0D4E/edit#gid=0\"\nownership = googlesheets4::read_sheet(ss)\n\n# ownership = read.csv(\"ownership.csv\")\n\n# reshape and remove players who did not submit a pick in the latest week - i.e. are eliminated\nown = ownership |>\n  pivot_longer(cols = -c(\"Player\"), names_to = \"week\", values_to = \"pick\") |> \n  filter(!is.na(pick)) |>\n  group_by(Player) |> \n  mutate(week = as.numeric(week), \n         max_week = max(week)) |> \n  ungroup()\n  \n# compute the proportion of people who have picked each team\nteam_ownership = df |> \n  group_by(team) |> \n  summarise(share = sum(team == own$pick, na.rm=T) / length(unique(own$Player))) # divide times picked by remaining players\n\nOWN_THRESH = 0.35\n\n# df |> \n#   left_join(team_ownership, by = \"team\") |> \n#   mutate(label = case_when(share >= OWN_THRESH ~ team, \n#                            TRUE ~ \"\")) |>\n#   filter(week %in% c(START_WEEK:NUM_WEEKS)) |>\n#   ggplot(aes(x = week, y = pwin, size = -share)) + \n#   geom_point(alpha = 0.6) + \n#   geom_text(aes(label = label), nudge_x = 0.3, size = 3) + \n#   labs(title = \"Team Win Probabilities by Team Ownership\", \n#        subtitle = \"The smaller the dot, the greater the number of players who can no longer pick that game\", \n#        x = \"Week Number\", \n#        y = \"Win Probability\", \n#        color = \"Ownership\", \n#        caption = sprintf(\"Names showing for teams with a greater than %s%% ownership\", OWN_THRESH*100)) + \n#   scale_color_viridis_c(labels = scales::percent_format(), option = color_scheme) + \n#   scale_x_continuous(breaks = START_WEEK:NUM_WEEKS) +\n#   scale_y_continuous(labels = scales::percent_format()) +\n#   theme(legend.position = \"none\")\n\n\n```\n\n## Results\n\nBelow are picks per entry, where picks which won their game are shown with red text. Once a player is removed, they no longer show up on the plot, and players are sorted in ascending order in terms of their average win probability - players higher in the plot have had lower win probabilities up to the shown week.\n\n```{r}\nown |> \n  select(Player, week, pick) |>\n  left_join(plot_data |> select(week, pick = team, pwin), \n            by = c(\"week\", \"pick\")) |> \n  left_join(eliminations |> mutate(upset = 1), \n            by = c(\"week\", \"pick\")) |> \n  group_by(Player) |> \n  mutate(label = pick, \n         max_week = max(week, na.rm = TRUE),\n         rank = mean(1-pwin, na.rm=TRUE) + max_week) |>\n  ungroup() |>\n  mutate(Player = reorder(Player, rank)) |> \n  ggplot(aes(x = week, y = Player, fill = pwin, label = label)) + \n  geom_tile(color = \"white\") + \n  geom_text(aes(label = label, color = is.na(upset)), size = 2.5) + \n  scale_color_manual(values = c(\"darkred\", \"white\")) +\n  scale_fill_viridis_c(option = color_scheme, label = scales::percent_format()) + \n  scale_x_continuous(breaks = 1:10, expand = c(0, 0), limits = c(0.5, 10)) + \n  theme(legend.position = c(.9,.75), \n        legend.background = element_blank()) +\n  labs(title = \"Weekly Picks, by win probabilities\", \n       subtitle = \"Players sorted by average win probability, upsets marked in red\",\n       x = \"Week\", \n       y = \"Pool Entries\", \n       fill = \"Win Probability\") + \n  guides(color = FALSE)\n```\n\nI followed the Opportunity Cost model recommendations for most of my picks. I swapped out the recommended New England in Week 4 for the New York Jets as none of the remaining players in the pool had yet to choose NE, and it is beneficial to separate yourself from the group given how often we see upsets. Unfortunately for me, it was the NYJ and not NE game that resulted in an upset.\n\nAnd just like that, that is a wrap for the 2022 Losers Pool! Big congrats to Drew2, Billy and DM who chose to split the pot following Week 7. Hopefully we can improve on our algorithms and selection process come the 2023 season. I think there is some value to be found in optimizing across multiple entries, as well as being able to shift from minimizing the risk of being eliminated to maximizing the expected value of a set of picks conditional on who the remaining players have left in the pool.\n\n<!-- We barely squeak through Week three with a last-minute comeback by the Minnesota Vikings (Hutch1 above) to edge out the Lions. We lose one of our entries however, we aren't that worse off as we went out with seven of the remaining 25 teams picking Jacksonville. This also means we are back to optimizing in terms of the single-entry method, which is a bit of a bummer. I think there is more improvements and exploration that can be done under the multi-entry model. -->\n\n<!-- ## Weekly Picks  -->\n\n<!-- With only 11 players remaining, we can consider reducing the range of weeks we want to optimize over, or at least should compare the outcomes under different week profiles.  -->\n\n<!-- ```{r} -->\n\n<!-- # read in data & remove past picks  -->\n\n<!-- df = read_data(path) |>  -->\n\n<!--   filter(!team %in% c(\"PIT\", \"CHI\", \"DET\")) -->\n\n<!-- picks_oc_mult = function(NUM_WEEKS = 12, START_WEEK = 4) { -->\n\n<!--   for (i in START_WEEK:NUM_WEEKS) { -->\n\n<!--     weeks = seq(START_WEEK, NUM_WEEKS, 1)[!seq(START_WEEK, NUM_WEEKS, 1) %in% picks$week] -->\n\n<!--     rankings = lapply(weeks, function(x) delta_mult(x, picks)) |> bind_rows() -->\n\n<!--     pick = rankings[rank(-rankings$score) == 1, ] -->\n\n<!--     picks = rbind(picks, pick) -->\n\n<!--   } -->\n\n<!--   arrange(picks, week) -->\n\n<!-- } -->\n\n<!-- profiles = data.frame() -->\n\n<!-- for(i in 8:12) { -->\n\n<!--   picks = data.frame() -->\n\n<!--   out = picks_by_oc(START_WEEK = 4, NUM_WEEKS = i) -->\n\n<!--   out$label = sprintf(\"Profile 4-%s\", i) -->\n\n<!--   profiles = rbind(profiles, out) -->\n\n<!-- } -->\n\n<!-- profiles |>  -->\n\n<!--   rename(Week = week) |>  -->\n\n<!--   tidyr::pivot_wider(id_cols = c(\"Week\"), names_from = \"label\", values_from = \"pick\", values_fill = \"\") |>  -->\n\n<!--   kbl(align = \"c\") |>  -->\n\n<!--   kable_paper(\"striped\") |>  -->\n\n<!--   add_header_above(c(\" \"=1, \"Week Profile\" = 5)) -->\n\n<!-- ``` -->\n\n<!-- There is no change in the optimal picks when optimizing from Week 8 until Week 11. Therefore, we do not need to worry about optimizing too far ahead this week.  -->\n\n<!-- Another point worth mentioning is that noone has picked NE in the pool yet, which means it is likely some players will select them, and it could be advantagous to pick the next best team this week. Below are the remaining teams I can select in Week 4, as well as their associated ownership by others remaining in the pool.  -->\n\n<!-- ```{r} -->\n\n<!-- # df |> -->\n\n<!-- #   filter(week == 4, -->\n\n<!-- #          !team %in% c(\"PIT\", \"CHI\", \"DET\")) |> -->\n\n<!-- #   arrange(pwin) |> -->\n\n<!-- #   select(team, pwin) |> -->\n\n<!-- #   left_join(team_ownership, by = \"team\") |> -->\n\n<!-- #   kbl(caption = \"Possible Picks in Week 4 and Ownership\", -->\n\n<!-- #       digits = 2) |> -->\n\n<!-- #   kable_paper(\"striped\") |> -->\n\n<!-- #   scroll_box(height = \"250px\") -->\n\n<!-- # correct ownership for eliminations -->\n\n<!-- own3 = own |>  -->\n\n<!--   filter(week < 4) -->\n\n<!-- team_ownership = own3 |>  -->\n\n<!--   mutate(eliminated = (week == 3 & pick %in% c(\"IND\", \"JAX\", \"DAL\"))) |>  -->\n\n<!--   group_by(Player) |>  -->\n\n<!--   mutate(drop = max(eliminated),  -->\n\n<!--          max_week = max(week)) |>  -->\n\n<!--   filter(drop == 0,  -->\n\n<!--          max_week == 3) |>  -->\n\n<!--   ungroup() |>  -->\n\n<!--   group_by(team = pick) |>  -->\n\n<!--   summarise(share = n() / 11) -->\n\n<!-- df |>  -->\n\n<!--   filter(week == 4,  -->\n\n<!--          !team %in% c(\"PIT\", \"CHI\", \"DET\")) |>  -->\n\n<!--   arrange(pwin) |>  -->\n\n<!--   select(team, pwin) |>  -->\n\n<!--   left_join(team_ownership, by = \"team\") |>  -->\n\n<!--   mutate(share = ifelse(is.na(share), 0, share)) |> -->\n\n<!--   ggplot(aes(x = share, y = pwin)) +  -->\n\n<!--   geom_point() +  -->\n\n<!--   ggrepel::geom_text_repel(aes(label = team), nudge_x = 0.015) +  -->\n\n<!--   scale_x_continuous(labels = scales::percent_format()) +  -->\n\n<!--   scale_y_continuous(labels = scales::percent_format()) +  -->\n\n<!--   labs(title = \"Comparing Win Probability with Proportion Already Selected\",  -->\n\n<!--        subtitle = \"Picks through Week 3\", -->\n\n<!--        x = \"Proportion previously picked\",  -->\n\n<!--        y = \"Win Probability\") -->\n\n<!-- ``` -->\n\n<!-- Our OC algorithm recommends to take NE, however it is naive to the picks already made by others in the pool. When we look at the ownership proportions, we can see that out of the remaining 11 players, 7 have already picked NYJ, and that none have picked JAX or NE. Additionally, we can see there is a large jump from JAX to NO, so we can expect at most 3 picks on NYJ, and the remaining 7 split between NE and JAX. Given last weeks JAX upset, I suspect less people will take JAX, and will instead hop on NE. Therefore, it is a matter of taking NYJ who are facing PIT, or I go with JAX who are facing the top PHI. I'm torn between the two, however think I should give myself the chance at winning if everyone splits on NE and JAX with the unlikely 8% chance. This comes at the cost of having greater risk in Week 6 as I'll have to go with DAL, but the increased risk there is likely worth avoiding another wave of possible eliminations. -->\n\n<!-- **Thursday update**  -->\n\n<!-- ```{r} -->\n\n<!-- own |>  -->\n\n<!--   ungroup() |>  -->\n\n<!--   filter(week == 4) |>  -->\n\n<!--   select(-c(max_week, week)) |>  -->\n\n<!--   group_by(pick) |>  -->\n\n<!--   summarise(n = n(), Players = paste(Player, collapse = \", \")) |>  -->\n\n<!--   arrange(desc(n)) |>  -->\n\n<!--   kbl(col.names = c(\"Pick\", \"N\", \"Entries\"), caption = \"Week 4 Picks\") |>  -->\n\n<!--   kable_paper(full_width = F) -->\n\n<!-- ``` -->\n\n<!-- Our predictions were nearly correct, there were a large share (7 of 11) players who took NE, only 1 took JAX, and the remaining two took BAL and MIA. Two of the non-NE picks came from players who had multiple entries into the competition, and had already taken NE.  -->\n\n<!-- By deviating from this group, we are in a fantastic position, as we gave up ~2.5% in order to move away from the crowd.  -->\n\n<!-- Now there is a roughly 20% chance we see a NE win, and a NYJ loss moving us onto next week with at most 3 other competitors. Fingers crossed, and onto week 5!  -->\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":{"html_document":{"toc":true,"toc_float":{"collapsed":false,"smooth_scroll":false},"code_folding":"hide"}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":{"light":["sandstone","../../_light.scss"],"dark":["sandstone","../../_dark.scss"]},"editor":"source","title":"NFL Losers Pool - 2022","date":"2022-09-07","slug":[],"categories":["R","Sports Analytics","Data Visualization"],"tags":["R","Sports Analytics","Data Visualization"],"meta_img":"image/image.png","description":"Optimizing fantasy picks in an annual NFL losers pool."},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}